{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "import keras \n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter = ',')\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y\n",
    "  \n",
    "foder = u\"E:/Jupyter File/UCR_TS_Archive_2015/\"\n",
    "\n",
    "#flist = ['Adiac', 'Beef', 'CBF', 'ChlorineConcentration', 'CinC_ECG_torso', 'Coffee', 'Cricket_X', 'Cricket_Y', 'Cricket_Z', \n",
    "#'DiatomSizeReduction', 'ECGFiveDays', 'FaceAll', 'FaceFour', 'FacesUCR', '50words', 'FISH', 'Gun_Point', 'Haptics', \n",
    "#'InlineSkate', 'ItalyPowerDemand', 'Lighting2', 'Lighting7', 'MALLAT', 'MedicalImages', 'MoteStrain', 'NonInvasiveFatalECG_Thorax1', \n",
    "#'NonInvasiveFatalECG_Thorax2', 'OliveOil', 'OSULeaf', 'SonyAIBORobotSurface', 'SonyAIBORobotSurfaceII', 'StarLightCurves', 'SwedishLeaf', 'Symbols', \n",
    "#'synthetic_control', 'Trace', 'TwoLeadECG', 'Two_Patterns', 'uWaveGestureLibrary_X', 'uWaveGestureLibrary_Y', 'uWaveGestureLibrary_Z', 'wafer', 'WordsSynonyms', 'yoga']\n",
    "\n",
    "#flist  = ['MiddlePhalanxTW']\n",
    "#for each in flist:\n",
    "each = 'Adiac'\n",
    "\n",
    "fname = each\n",
    "x_train, y_train = readucr(foder+fname+'/'+fname+'_TRAIN')\n",
    "x_test, y_test = readucr(foder+fname+'/'+fname+'_TEST')\n",
    "\n",
    "###################################################################################################################\n",
    "'''模型变量'''\n",
    "nb_epochs = 40\n",
    "nb_feature = 0\n",
    "nb_classes = len(np.unique(y_test))\n",
    "nb_feature = x_train.shape[1]\n",
    "batch_size = min(x_train.shape[0]/10, 16)\n",
    "####################################################################################################################\n",
    "\n",
    "y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
    "y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "x_train = (x_train - x_train_mean)/(x_train_std) \n",
    "x_test = (x_test - x_train_mean)/(x_train_std)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape + (1,1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# x_train.shape:  (390, 176, 1, 1)\n",
      "# x_test.shape:  (391, 176, 1, 1)\n",
      "# Y_train.shape:  (390, 37)\n",
      "# Y_test.shape:  (391, 37)\n"
     ]
    }
   ],
   "source": [
    "print(\"# x_train.shape: \",x_train.shape)\n",
    "print(\"# x_test.shape: \",x_test.shape)\n",
    "\n",
    "print(\"# Y_train.shape: \",Y_train.shape)\n",
    "print(\"# Y_test.shape: \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_Sequential模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''CNN'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "# 全局变量\n",
    "batch_size = batch_size\n",
    "nb_classses = nb_classes\n",
    "epochs = nb_epochs\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = x_train.shape[1], x_train.shape[2]\n",
    "# number of convolutional filters to use\n",
    "nb_filters_1 = 128\n",
    "nb_filters_2 = 256\n",
    "nb_filters_3 = 128\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (3,1)\n",
    "# convolution kernel size\n",
    "kernel_size_1 = (8,1)\n",
    "kernel_size_2 = (5,1)\n",
    "kernel_size_3 = (3,1)\n",
    "\n",
    "input_shape = (x_train.shape[1:])\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_5: expected ndim=3, found ndim=4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-a1bb0d3aa014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#model.add(MaxPooling2D(pool_size=pool_size)) #池化层\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    473\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[0;32m    474\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;31m# modify the input spec to include the state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRecurrent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    455\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_5: expected ndim=3, found ndim=4"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "\n",
    "model.add(Convolution2D(nb_filters_1, (kernel_size_1[0], kernel_size_2[1]), padding='same', input_shape=input_shape)) # 卷积层1  \n",
    "model.add(Activation('relu')) #激活层  \n",
    "\n",
    "model.add(Convolution2D(nb_filters_2, (kernel_size_2[0], kernel_size_2[1]))) #卷积层2  \n",
    "model.add(Activation('relu')) #激活层\n",
    "\n",
    "model.add(Convolution2D(nb_filters_3, (kernel_size_3[0], kernel_size_3[1]))) #卷积层3  \n",
    "model.add(Activation('relu')) #激活层\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=pool_size)) #池化层  \n",
    "\n",
    "\n",
    "model.add(Reshape((176, nb_filters_3)))\n",
    "model.add(LSTM(8))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.25)) #神经元随机失活  \n",
    "model.add(Flatten()) #拉成一维数据  \n",
    "model.add(Dense(128)) #全连接层1  \n",
    "model.add(Activation('relu')) #激活层  \n",
    "model.add(Dropout(0.5)) #随机失活  \n",
    "model.add(Dense(nb_classes)) #全连接层2  \n",
    "model.add(Activation('softmax')) #Softmax评分  \n",
    "  \n",
    "#编译模型  \n",
    "model.compile(loss='categorical_crossentropy',  \n",
    "              optimizer='adadelta',  \n",
    "              metrics=['accuracy'])  \n",
    "\n",
    "#训练模型  \n",
    "model.fit(x_train, Y_train, batch_size=batch_size, epochs=epochs,  \n",
    "          verbose=1, validation_data=(x_test, Y_test))  \n",
    "#评估模型  \n",
    "score = model.evaluate(x_test, Y_test, verbose=0)  \n",
    "print('Test score:', score[0])  \n",
    "print('Test accuracy:', score[1])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model_函数式模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (8, 1), padding=\"same\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (5, 1), padding=\"same\")`\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 1), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################\n",
      "输出测试 conv1 —— feature map: \n",
      "Tensor(\"activation_49/Relu:0\", shape=(?, 176, 1, 128), dtype=float32)\n",
      "##################################\n",
      "输出测试 conv2 —— feature map: \n",
      "Tensor(\"activation_50/Relu:0\", shape=(?, 176, 1, 256), dtype=float32)\n",
      "##################################\n",
      "输出测试 conv3 —— feature map: \n",
      "Tensor(\"activation_51/Relu:0\", shape=(?, 176, 1, 128), dtype=float32)\n",
      "###################################\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-e6cde7892f8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"###################################\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mfull\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[0mfull\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    " \n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras \n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ReduceLROnPlateau \n",
    "\n",
    "filters_1 = 128\n",
    "filters_2 = 256\n",
    "filters_3 = 128\n",
    "\n",
    "kernel_size_1 = (8,1)\n",
    "kernel_size_2 = (5,1)\n",
    "kernel_size_3 = (3,1)\n",
    "\n",
    "x = keras.layers.Input(x_train.shape[1:])\n",
    "\n",
    "#    drop_out = Dropout(0.2)(x)\n",
    "conv1 = keras.layers.Conv2D(128, (8, 1), border_mode='same')(x)\n",
    "conv1 = keras.layers.normalization.BatchNormalization()(conv1)\n",
    "conv1 = keras.layers.Activation('relu')(conv1)\n",
    "\n",
    "print(\"##################################\")\n",
    "print(\"输出测试 conv1 —— feature map: \")\n",
    "print(conv1)\n",
    "print(\"##################################\")\n",
    "\n",
    "#    drop_out = Dropout(0.2)(conv1)\n",
    "conv2 = keras.layers.Conv2D(256, (5, 1), border_mode='same')(conv1)\n",
    "conv2 = keras.layers.normalization.BatchNormalization()(conv2)\n",
    "conv2 = keras.layers.Activation('relu')(conv2)\n",
    "\n",
    "print(\"输出测试 conv2 —— feature map: \")\n",
    "print(conv2)\n",
    "print(\"##################################\")\n",
    "\n",
    "#    drop_out = Dropout(0.2)(conv2)\n",
    "conv3 = keras.layers.Conv2D(128, (3, 1), border_mode='same')(conv2)\n",
    "conv3 = keras.layers.normalization.BatchNormalization()(conv3)\n",
    "conv3 = keras.layers.Activation('relu')(conv3)\n",
    "\n",
    "print(\"输出测试 conv3 —— feature map: \")\n",
    "print(conv3)\n",
    "print(\"###################################\")\n",
    "\n",
    "full = keras.layers.Reshape(conv3.shape[1], conv3.shape[2], conv3.shape[3])(conv3)\n",
    "full = LSTM(8, input_shape=(full.shape[1], full.shape[2]), return_sequences=True)(conv3)\n",
    "\n",
    "#full = keras.layers.pooling.GlobalAveragePooling2D()(conv3)\n",
    "\n",
    "out = keras.layers.Dense(nb_classes, activation='softmax')(full)\n",
    "\n",
    "model = Model(input=x, output=out)\n",
    " \n",
    "optimizer = keras.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'loss', factor=0.5,\n",
    "                  patience=50, min_lr=0.0001) \n",
    "hist = model.fit(x_train, Y_train, batch_size=batch_size, nb_epoch=nb_epochs,\n",
    "          verbose=1, validation_data=(x_test, Y_test), callbacks = [reduce_lr])\n",
    "#Print the testing results which has the lowest training loss.\n",
    "log = pd.DataFrame(hist.history)\n",
    "print(log.loc[log['loss'].idxmin]['loss'], log.loc[log['loss'].idxmin]['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新的 1D卷积+1LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, PReLU, Dense, LSTM, multiply, concatenate, Activation\n",
    "from keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Permute, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    ip = Input(shape=(1, 176))  #  timesteps, nb_feature/length_sequence\n",
    "\n",
    "    x = LSTM(8)(ip)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
