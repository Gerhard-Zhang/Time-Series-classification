{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    ip = Input(shape=(1, 176))  #  timesteps, nb_feature/length_sequence\n",
    "\n",
    "    x = LSTM(8)(ip)\n",
    "    x = Dropout(0.8)(x)\n",
    "\n",
    "    y = Permute((2, 1))(ip)\n",
    "    y = Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    x = concatenate([x, y])\n",
    "\n",
    "    out = Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, out)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # add load model code here to fine-tune\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', patience=100, mode='max', factor=factor, cooldown=0, min_lr=1e-4, verbose=2)\n",
    "\n",
    "callback_list = [model_checkpoint, reduce_lr]\n",
    "\n",
    "optm = Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=callback_list,\n",
    "              class_weight=class_weight, verbose=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optm = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(optimizer=optm, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"\\nEvaluating : \")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "print()\n",
    "print(\"Final Accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter = ',')\n",
    "    Y = data[:,0]\n",
    "    X = data[:,1:]\n",
    "    return X, Y\n",
    "  \n",
    "foder = u\"E:/Jupyter File/UCR_TS_Archive_2015/\"\n",
    "\n",
    "#flist = ['Adiac', 'Beef', 'CBF', 'ChlorineConcentration', 'CinC_ECG_torso', 'Coffee', 'Cricket_X', 'Cricket_Y', 'Cricket_Z', \n",
    "#'DiatomSizeReduction', 'ECGFiveDays', 'FaceAll', 'FaceFour', 'FacesUCR', '50words', 'FISH', 'Gun_Point', 'Haptics', \n",
    "#'InlineSkate', 'ItalyPowerDemand', 'Lighting2', 'Lighting7', 'MALLAT', 'MedicalImages', 'MoteStrain', 'NonInvasiveFatalECG_Thorax1', \n",
    "#'NonInvasiveFatalECG_Thorax2', 'OliveOil', 'OSULeaf', 'SonyAIBORobotSurface', 'SonyAIBORobotSurfaceII', 'StarLightCurves', 'SwedishLeaf', 'Symbols', \n",
    "#'synthetic_control', 'Trace', 'TwoLeadECG', 'Two_Patterns', 'uWaveGestureLibrary_X', 'uWaveGestureLibrary_Y', 'uWaveGestureLibrary_Z', 'wafer', 'WordsSynonyms', 'yoga']\n",
    "\n",
    "#flist  = ['MiddlePhalanxTW']\n",
    "#for each in flist:\n",
    "each = 'Adiac'\n",
    "\n",
    "fname = each\n",
    "x_train, y_train = readucr(foder+fname+'/'+fname+'_TRAIN')\n",
    "x_test, y_test = readucr(foder+fname+'/'+fname+'_TEST')\n",
    "\n",
    "###################################################################################################################\n",
    "'''模型变量'''\n",
    "nb_epochs = 40\n",
    "nb_feature = 0\n",
    "nb_classes = len(np.unique(y_test))\n",
    "nb_feature = x_train.shape[1]\n",
    "batch_size = min(x_train.shape[0]/10, 16)\n",
    "####################################################################################################################\n",
    "\n",
    "y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
    "y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "x_train_mean = x_train.mean()\n",
    "x_train_std = x_train.std()\n",
    "x_train = (x_train - x_train_mean)/(x_train_std) \n",
    "x_test = (x_test - x_train_mean)/(x_train_std)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape + (1,1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"# x_train.shape: \",x_train.shape)\n",
    "print(\"# x_test.shape: \",x_test.shape)\n",
    "\n",
    "print(\"# Y_train.shape: \",Y_train.shape)\n",
    "print(\"# Y_test.shape: \",Y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
